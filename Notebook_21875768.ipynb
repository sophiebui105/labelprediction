{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3-j_LTPdFvj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/PaulHancock/COMP5009_pracs/raw/main/data/Assignment2024.sqlite"
      ],
      "metadata": {
        "id": "NLT9DbGzeK6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con = sqlite3.connect('Assignment2024.sqlite')\n",
        "train_df = pd.read_sql(\"SELECT * FROM train\", con)\n"
      ],
      "metadata": {
        "id": "eF_TlEpdeNSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "gVVoKPHAePrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_sql(\"SELECT * FROM test\", con)"
      ],
      "metadata": {
        "id": "NdO5VpTgfDZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "OYPVDchqfHpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(5)"
      ],
      "metadata": {
        "id": "WpYeyx37KbJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column Names\")\n",
        "print(train_df.columns)\n",
        "print()\n",
        "print(\"Data types\")\n",
        "print(train_df.dtypes)"
      ],
      "metadata": {
        "id": "GTEoXk_SfIsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column Names\")\n",
        "print(test_df.columns)\n",
        "print()\n",
        "print(\"Data types\")\n",
        "print(test_df.dtypes)"
      ],
      "metadata": {
        "id": "638BMvs9KwMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "SnazEUie3Ual"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "f5RIrC0zLgm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "iIW4_ytz4Yv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.describe()"
      ],
      "metadata": {
        "id": "J1bl6mW-4sQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Identify missing values\n",
        "def missing(df):\n",
        "  missing_dict = dict()\n",
        "  total = df.shape[0]\n",
        "  for attribute in df.columns:\n",
        "    missing = df[attribute].isna().sum()\n",
        "    frac = missing/total * 100\n",
        "    missing_dict[attribute] = frac\n",
        "  return missing_dict"
      ],
      "metadata": {
        "id": "0BMbWgQlMyam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_dict = missing(train_df)\n",
        "m_dict"
      ],
      "metadata": {
        "id": "eTls_s2JUBtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_dict_test = missing(test_df)\n",
        "m_dict_test"
      ],
      "metadata": {
        "id": "6Hxr8iJCbLFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Drop missing values if the missing values > 20 %\n",
        "cols_to_drop = [ att for att,frac in m_dict.items() if frac >20]\n",
        "cols_to_drop"
      ],
      "metadata": {
        "id": "-9etri_oUvBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = ['Office', 'Oven']\n",
        "train_df.drop(columns=cols_to_drop,\n",
        "           inplace=True)"
      ],
      "metadata": {
        "id": "9Y_odg9Qbtwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=cols_to_drop,\n",
        "           inplace=True)"
      ],
      "metadata": {
        "id": "JDo8YQxb2Z-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Replace missing values\n",
        "cols_to_impute = [ att for att,frac in m_dict.items() if 0<frac <5]\n",
        "cols_to_impute"
      ],
      "metadata": {
        "id": "yvoBoVSlk_A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cols_to_impute:\n",
        "  mean = train_df[col].mean()\n",
        "  train_df[col].fillna(mean, inplace=True)"
      ],
      "metadata": {
        "id": "BeHsECQRlWG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_dict = missing(train_df)\n",
        "for col in cols_to_impute:\n",
        "  print(col, \"missing data\", m_dict[col])"
      ],
      "metadata": {
        "id": "V-vN99iPlfRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Identify duplicates\n",
        "dups_train = train_df[train_df.iloc[:,1:].duplicated()]\n",
        "dups_train"
      ],
      "metadata": {
        "id": "pDQAWD_Da3Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dups_test = test_df[test_df.iloc[:,1:].duplicated()]\n",
        "dups_test"
      ],
      "metadata": {
        "id": "Depk0YcvdoF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dups_test.sum()"
      ],
      "metadata": {
        "id": "My_Rf6rKd6vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df1 = train_df.drop_duplicates(subset=train_df.columns[1:], keep='first')"
      ],
      "metadata": {
        "id": "6vVOLjwvGW2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df1.shape"
      ],
      "metadata": {
        "id": "DfTVBVj2GnE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "MSG = train_df1[['Music', 'Storage', 'Guitar']]\n",
        "le_dict = {}\n",
        "\n",
        "for col in MSG.columns:\n",
        "    le = LabelEncoder()\n",
        "    MSG[col] = le.fit_transform(MSG[col])\n",
        "    le_dict[col] = le\n",
        "\n",
        "print(MSG)\n",
        "\n",
        "\n",
        "MSG_test = test_df[['Music', 'Storage', 'Guitar']]\n",
        "\n",
        "for col in MSG_test.columns:\n",
        "    MSG_test[col] = le_dict[col].transform(MSG_test[col])\n",
        "\n",
        "print(MSG_test)\n"
      ],
      "metadata": {
        "id": "rN8WU66WKGVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(MSG.columns)\n",
        "train_df_encode = pd.get_dummies(MSG, drop_first = True, columns = MSG.columns)\n",
        "test_df_encode = pd.get_dummies(MSG_test, drop_first = True, columns = MSG_test.columns)\n",
        "train_df_encode = train_df_encode.astype(int)\n",
        "test_df_encode = test_df_encode.astype(int)\n",
        "train_df_encode, test_df_encode = train_df_encode.align(test_df_encode, fill_value=0, axis=1)\n",
        "print(train_df_encode.head())\n",
        "print(test_df_encode.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UQf4f1nSr6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extract numeric attributes\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "DNuiCuR7ThS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_attributes = train_df1.select_dtypes(include='number').columns\n",
        "numeric_attributes\n"
      ],
      "metadata": {
        "id": "6dvoY2c9-B3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_attributes_test = test_df.select_dtypes(include='number').columns\n",
        "numeric_attributes_test"
      ],
      "metadata": {
        "id": "vv3rpX9OPaYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Feature extraction\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YRVjxvyGVCWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_train_df = train_df1[numeric_attributes]\n",
        "numeric_test_df = test_df[numeric_attributes_test]\n",
        "numeric_test_df.head()"
      ],
      "metadata": {
        "id": "yNQx9T4E60fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor = numeric_train_df.corr()\n",
        "high_corr = cor[(cor > 0.8) | (cor < -0.8)]\n",
        "fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
        "sns.heatmap(high_corr, annot=False, cmap=plt.cm.rainbow, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1f3A-a_O2oCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['index', 'System', 'Knowledge','Guidance','Virus','Insect','Cookie','Moment','Problem']\n",
        "train_df2 = numeric_train_df.drop(columns=columns_to_drop, errors='ignore')\n",
        "train_df2\n",
        "test_df2 = numeric_test_df.drop(columns=columns_to_drop, errors='ignore')\n",
        "test_df2"
      ],
      "metadata": {
        "id": "Cn6qWGdpC_hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df3 = pd.concat([train_df2, train_df_encode], axis = 1)"
      ],
      "metadata": {
        "id": "hk82aAir4QFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df3.columns"
      ],
      "metadata": {
        "id": "dOF3-9R83UQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df3 = pd.concat([test_df2, test_df_encode], axis = 1)"
      ],
      "metadata": {
        "id": "8e_SP7fgyQop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df3.columns"
      ],
      "metadata": {
        "id": "m3EneuixDCW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df3 = pd.concat([train_df2.reset_index(drop=True), train_df_encode.reset_index(drop=True)], axis=1)"
      ],
      "metadata": {
        "id": "GjPjkmYnoLTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df3.shape"
      ],
      "metadata": {
        "id": "uSaNkQF1Rj3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df3.columns"
      ],
      "metadata": {
        "id": "b3w0UUL3CgK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df3.columns"
      ],
      "metadata": {
        "id": "5UdRHZWw4O7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Class Imbalance\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bnLeeWyPxLXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['class'].unique())\n",
        "class_counts = train_df['class'].value_counts()\n",
        "print(class_counts)"
      ],
      "metadata": {
        "id": "dt5osHmtxQKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Instances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H_XWyZiByJJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Stratified K-fold to split data\n",
        "!pip install scikit-learn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=10)"
      ],
      "metadata": {
        "id": "vc5Y-6Voc1oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "cmap_data = plt.cm.Paired\n",
        "cmap_cv = plt.cm.coolwarm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rr3n1pC_ekxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
        "    for ii, (train_idx, test_idx) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[test_idx] = 1\n",
        "        indices[train_idx] = 0\n",
        "\n",
        "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
        "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
        "                   vmin=-.2, vmax=1.2)\n",
        "\n",
        "    ax.scatter(range(len(X)), [n_splits + 1.5] * len(X),\n",
        "               c=y, marker='_', lw=lw, cmap=cmap_data)\n",
        "\n",
        "    yticklabels = list(range(n_splits)) + ['class']\n",
        "    if group is not None:\n",
        "      yticklabels.append('group')\n",
        "\n",
        "    ax.set(yticks=np.arange(n_splits+ (2 if group is not None else 1)) + .5, yticklabels=yticklabels,\n",
        "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
        "           ylim=[n_splits+(2 if group is not None else 1) + 0.2, -0.2])\n",
        "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
        "    return ax"
      ],
      "metadata": {
        "id": "bXJolLcGezmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Using SMOTE to balance data\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "vG1GDrFOsvxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df3.drop('class', axis=1)\n",
        "y_train = train_df3['class']"
      ],
      "metadata": {
        "id": "U6pGJVNYud7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "gY1EkpASuiDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.Series(y_train_smote).value_counts())"
      ],
      "metadata": {
        "id": "VrAS8OjauotH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df4 = pd.concat([X_train_smote.reset_index(drop=True), y_train_smote.reset_index(drop=True)], axis=1)\n",
        "train_df4"
      ],
      "metadata": {
        "id": "7KgGDddwyOgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Standardization\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "iOG0JS4guukM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_column = train_df4['class']\n",
        "class_column"
      ],
      "metadata": {
        "id": "yPGOouPtRk7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.columns)\n",
        "class_column_test = test_df['class']\n",
        "class_column_test"
      ],
      "metadata": {
        "id": "eNh4zkelvO1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df4.drop(columns='class', inplace=True, errors='ignore')\n",
        "train_df4.columns\n",
        "train_non_categorial_columns = train_df4.select_dtypes(exclude='object').columns\n",
        "train_non_categorial_columns"
      ],
      "metadata": {
        "id": "OL7QDUKV1SNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df3.drop(columns=['index' ,'class'], inplace = True, errors='ignore')\n",
        "test_df3.columns\n",
        "test_non_categorial_columns = test_df3.select_dtypes(exclude='object').columns\n",
        "test_non_categorial_columns"
      ],
      "metadata": {
        "id": "RTV3i1L31pTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(train_df4)\n",
        "\n",
        "train_df4_scaled = scaler.transform(train_df4)\n",
        "test_df3_scaled = scaler.transform(test_df3)\n"
      ],
      "metadata": {
        "id": "xSkRUx6Vwzgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df4_scaled"
      ],
      "metadata": {
        "id": "dkR8458lSgba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df4_scaled = pd.DataFrame(train_df4_scaled, columns=train_non_categorial_columns)\n",
        "class_column\n",
        "train_df4_scaled['class'] = class_column"
      ],
      "metadata": {
        "id": "VgsYCrBtRqAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df4_scaled"
      ],
      "metadata": {
        "id": "V0UWb3y_Spi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KNN classifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "fabbJ9q5G0Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df4_scaled"
      ],
      "metadata": {
        "id": "__lqtR5SQiie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df4_scaled)"
      ],
      "metadata": {
        "id": "Y_B-XTfDX2Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df4_scaled.drop(columns=['class'], errors = 'ignore')\n",
        "y = train_df4_scaled['class']\n"
      ],
      "metadata": {
        "id": "4zNe7FxCG_NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=10)"
      ],
      "metadata": {
        "id": "GPvx4vo0Imns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "fig, ax = plt.subplots(2,5, figsize=(18,6))\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    parameters = {'weights': ['uniform','distance'],\n",
        "              'n_neighbors':[1,3,7,11,17,21]}\n",
        "\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    gscv = GridSearchCV(estimator=knn,\n",
        "                    param_grid=parameters,\n",
        "                    cv=skf,\n",
        "                    scoring='accuracy')\n",
        "\n",
        "    best_knn = gscv.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = best_knn.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    scores.append(accuracy)\n",
        "    ConfusionMatrixDisplay.from_estimator(best_knn, X_test, y_test,\n",
        "                                          display_labels=y.unique(),  # Use unique class labels from y\n",
        "                                          ax=ax.ravel()[i])\n",
        "\n",
        "    print(f\"Fold accuracy: {accuracy}\")\n",
        "\n",
        "print(f\"Average accuracy: {sum(scores) / len(scores)}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E3ENbvK9d_XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_knn.best_params_, best_knn.best_score_"
      ],
      "metadata": {
        "id": "YoMP94PA0JjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Decision Tree\n",
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "jW5Ygl1wZs9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "\n",
        "fig, ax = plt.subplots(2,5, figsize=(18,6))\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    parameters = {'criterion': ('gini','entropy'),\n",
        "                  'min_samples_split':[3,10,15,20]}\n",
        "\n",
        "    dtc = tree.DecisionTreeClassifier()\n",
        "\n",
        "    gscv = GridSearchCV(estimator=dtc,\n",
        "                    param_grid=parameters,\n",
        "                    cv=skf,\n",
        "                    scoring='accuracy')\n",
        "\n",
        "    best_dtc = gscv.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = best_dtc.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    scores.append(accuracy)\n",
        "\n",
        "    ConfusionMatrixDisplay.from_estimator(best_dtc, X_test, y_test, ax=ax.ravel()[i])\n",
        "\n",
        "    print(f\"Fold accuracy: {accuracy}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"Average accuracy: {sum(scores) / len(scores)}\")\n",
        "best_dtc.best_params_, best_dtc.best_score_"
      ],
      "metadata": {
        "id": "FFsiB7prj7Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = tree.DecisionTreeClassifier(criterion=best_dtc.best_params_['criterion'],\n",
        "                                  min_samples_split=best_dtc.best_params_['min_samples_split'])\n",
        "dtc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Du895us6NwHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Naive Bayes\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "X = train_df4_scaled.drop(columns=['class'])\n",
        "y = train_df4_scaled['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "model = GaussianNB()\n",
        "\n",
        "cv_scores = []\n",
        "\n",
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    y_val_pred = model.predict(X_val_fold)\n",
        "\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    cv_scores.append(accuracy)\n",
        "    print(f\"Fold accuracy: {accuracy}\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test accuracy on unseen data: {test_accuracy}\")\n",
        "\n",
        "print(f\"Average cross-validation accuracy: {sum(cv_scores) / len(cv_scores)}\")"
      ],
      "metadata": {
        "id": "S0Qj4IRLbuRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Random Forest classifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X = train_df4_scaled.drop(columns=['class'])\n",
        "y = train_df4_scaled['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "parameters = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10, 20],\n",
        "}\n",
        "\n",
        "model = RandomForestClassifier(criterion='gini',random_state=42)\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=parameters,\n",
        "                                   n_iter=4, cv=skf, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "cv_scores = []\n",
        "\n",
        "fig, ax = plt.subplots(1, 5, figsize=(18, 6))\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    y_val_pred = random_search.predict(X_val_fold)\n",
        "\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    cv_scores.append(accuracy)\n",
        "\n",
        "    ConfusionMatrixDisplay.from_estimator(random_search, X_val_fold, y_val_fold, ax=ax.ravel()[i])\n",
        "\n",
        "    print(f\"Fold accuracy: {accuracy}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(f\"Best parameters found: {best_params}\")\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test accuracy on unseen data: {test_accuracy}\")\n",
        "\n",
        "print(f\"Average cross-validation accuracy: {sum(cv_scores) / len(cv_scores)}\")\n"
      ],
      "metadata": {
        "id": "mLfDR3sBbNEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Predict on test value using Radom Forest\n",
        "test_df3_scaled = pd.DataFrame(test_df3_scaled, columns=test_non_categorial_columns)\n",
        "test_df3_scaled_500 = test_df3_scaled.head(500)\n",
        "test_df3_scaled_500"
      ],
      "metadata": {
        "id": "_hGXMBiSu_uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Acl779T2avT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_rf = rf_model.predict(test_df3_scaled_500)\n"
      ],
      "metadata": {
        "id": "CM-4XSKVbq6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_rf_df = pd.DataFrame(predictions_rf, columns=['Predicted_Class_Random Forest'])"
      ],
      "metadata": {
        "id": "sTgusrMgcXT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_rf_df"
      ],
      "metadata": {
        "id": "wkeDSUB6cdRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Predict test value using KNN\n",
        "!pip install scikit-learn==1.1.2 missingpy==0.2.0\n",
        "import sklearn.neighbors._base\n",
        "import sys\n",
        "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
        "from missingpy import KNNImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "best_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "best_knn.fit(imputer.fit_transform(X_train), y_train)\n",
        "predictions_knn_df = best_knn.predict(imputer.fit_transform(test_df3_scaled_500))"
      ],
      "metadata": {
        "id": "KKmebzFDdH6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_knn_df = pd.DataFrame(predictions_knn_df, columns=['Predicted_Class_KNN'])"
      ],
      "metadata": {
        "id": "wjNnd4Q2hdz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_knn_df"
      ],
      "metadata": {
        "id": "SciO7W-2heUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = pd.concat([predictions_rf_df, predictions_knn_df], axis=1)"
      ],
      "metadata": {
        "id": "7YPyfj8Phqj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions.to_csv('all_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "O89GwFF8h8Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "p8m6J9t9iDjW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}